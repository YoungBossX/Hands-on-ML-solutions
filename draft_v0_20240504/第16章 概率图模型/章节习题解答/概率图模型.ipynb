{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 以下关于概率图模型的说法错误的是：   \n",
    "A. 图分有向图和无向图两种，分别表示变量间的单向和双向依赖关系。   \n",
    "B. 概率图的有效建立往往需要人的先验知识。   \n",
    "C. 贝叶斯网络导出的MAP和MLE解是等价的。   \n",
    "D. 马尔可夫网络中势能越高的状态出现的概率越低。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：    \n",
    "A.正确。有向图可以表示因果关系和单项依赖关系，无向图表示双向依赖关系，不指定依赖方向。  \n",
    "B.正确。概率题一般需要人的先验知识来设计图结构、表示变量之间的关系和条件概率分布等。  \n",
    "C.错误。MAP和MLE在某些情况下导出的解是相同的，MLE是寻找参数的估计值，使得观测数据出现的概率最大，MAP同时考虑了参数的先验概率。在有些情况下，先验概率会使得MAP和MLE的解不一样，所以不能说是等价的。  \n",
    "D.正确。马尔可夫网络中，状态的概率分布用势能函数表示，势能函数值越高对应状态出现的概率越低。状态粉笔和势能成反比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 以下关于条件独立的说法，不正确的是？   \n",
    "A. 条件独立的定义是：考虑3个变量$a,b,c$假设给定$b$和$c$的情况下，$a$的条件分布不依赖于$b$的值，则在给定$c$的情况下$a$条件独立于$b$。   \n",
    "B. 图模型中的尾对尾结构中，当父节点未被观测到时，其子节点之间将不会条件独立   \n",
    "C. 图模型中的头对尾结构中，当中间节点未被观测到时，其两头的节点之间将不会条件独立   \n",
    "D. 图模型中的头对头结构中，当子节点未被观测到时，其父节点之间将不会条件独立  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "A.错误。条件独立的定义是：考虑三个变量$a,b,c$，在给定$c$的情况下，$a$的条件分布不依赖于$b$的值，那么在给定$c$的情况下$a$条件独立于$b$。    \n",
    "B.正确。尾对尾结构中，父节点未被观测到，父节点包含两个子节点的信息，两个子节点就存在了间接的关联，而不会条件独立。  \n",
    "C.正确。头对尾结构，一个变量是另一个变量的父节点。当中间节点未被观测，两头的节点就会因为中间的节点而存在依赖关系，不会条件独立。  \n",
    "D.正确。头对头结构中，子节点未被观测，父节点依赖于子结构，不会条件独立。 \n",
    "\n",
    "在概率图模型中，未观测的节点包含了其他节点的信息，会使得节点变量之间产生关联，被观测后，就确定了这些信息，使得其他节点变量条件独立（不会因为另一个节点变化而产生未知信息相互影响）     \n",
    "![3个变量的依赖关系](https://hml.boyuai.com/static/cond_ind.drawio.68e92fbc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 在线性模型中，假设参数$w$的先验分布是偏移参数为$\\mu=0$、尺度参数为$b$的拉普拉斯分布，其概率密度函数为\n",
    "$$p(w|\\mu=0,b)=\\frac{1}{2b}\\exp(-\\frac{|w|}{b})$$\n",
    "仿照 16.2 节中的推导（此处原书为16.1应更改为16.2，利用MAP求解此时的优化目标。这个目标相当于为线性模型添加了什么正则化约束？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bm{y}和\\bm{w}的概率分布:$\n",
    "$$\n",
    "p(\\bm{y}, \\bm{w}|\\bm{X}) = p(\\bm{y}\\bm{w},\\bm{X}) p(\\bm{w}) = p(\\bm{w})\\prod_{i=1}^{N}p(y_i|\\bm{w},\\bm{x}_i) \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "$根据贝叶斯公式，模型参数\\bm{w}的后验分布表示为：$\n",
    "$$\n",
    "p(\\bm{w}|\\bm{X},\\bm{y})=\\frac{p(\\bm{y}, \\bm{w}|\\bm{X})p(\\bm{w})}{p(\\bm{y}|\\bm{X})} \\propto p(\\bm{w}) \\prod_{i=1}^{N}p(y_i|\\bm{w}, \\bm{x}_i)\n",
    "$$\n",
    "$\\\\$\n",
    "$设参数\\bm{w}的先验分布是偏移参数为\\mu=0，尺度参数为b的拉普拉斯分布，概率分布：$\n",
    "$$p(\\bm{w}|\\mu=0,b)=\\frac{1}{2b}\\exp(-\\frac{|\\bm{w}|}{b})$$\n",
    "$即\\bm{w} 服从拉普拉斯分布，表示为 \\bm{w} \\sim \\text{Laplace}(0, b)$\n",
    "\n",
    "\n",
    "$假设y_i和\\bm{x}_i和\\bm{w}之间的关系服从高斯分布，满足：$\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i &\\sim \\mathcal{N}(\\bm{x}_i^T \\bm{w}, \\sigma^2) \\\\\n",
    "p(y_i | \\bm{x}_i, \\bm{w}, \\sigma^2) &\\sim \\mathcal{N}(y_i | \\bm{x}_i^T \\bm{w}, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - \\bm{w}^T\\bm{x}_i)^2}{2\\sigma^2})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "$那么后验分布可以表示为：$\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\bm{w}|\\bm{X},\\bm{y}) & \\propto p(\\bm{w}) \\prod_{i=1}^{N}p(y_i|\\bm{w}, \\bm{x}_i) \n",
    "\\\\\n",
    "& \\propto p(\\bm{w} | \\mu=0,b) \\prod_{i=1}^{N} p(y_i | \\bm{x}_i, \\bm{w}, \\sigma^2)\n",
    "\\\\\n",
    "& = p(\\bm{w} | \\mu=0,b) \\prod_{i=1}^{N} \\mathcal{N}(y_i | \\bm{x}_i^T \\bm{w}, \\sigma^2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$最大后验估计MAP：$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\max_{\\bm{w}} p(\\bm{w}|\\bm{X}, \\bm{y}) \n",
    "& = \\arg \\max_{\\bm{w}} \\left( p(\\bm{w} | \\mu=0,b) \\prod_{i=1}^{N} \\mathcal{N}(y_i | \\bm{x}_i^T \\bm{w}, \\sigma^2)\\right)\n",
    "\\\\\n",
    "& = \\arg \\max_{\\bm{w}} \\left(\\frac{1}{2b}\\exp(-\\frac{|\\bm{w}|}{b}) \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - \\bm{w}^T\\bm{x}_i)^2}{2\\sigma^2})\\right)\n",
    "\\\\\n",
    "&\\text{取对数，连乘变连加}\n",
    "\\\\\n",
    "& = \\arg\\max_{\\bm{w}}\\log \\left(\\frac{1}{2b}\\exp(-\\frac{|\\bm{w}|}{b}) \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - \\bm{w}^T\\bm{x}_i)^2}{2\\sigma^2})\\right)\n",
    "\\\\\n",
    "& = \\arg\\max_{\\bm{w}} \\left(\\log(\\frac{1}{2b}\\exp(-\\frac{|\\bm{w}|}{b})) \\sum_{i=1}^{N}\\log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - \\bm{w}^T\\bm{x}_i)^2}{2\\sigma^2}))\\right)\n",
    "\\\\\n",
    "& \\log(\\frac{1}{2b})\\text{和}\\log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})\\text{是常数，对}\\bm{w}\\text{没影响，可以忽略}\n",
    "\\\\\n",
    "& = \\arg\\max_{\\bm{w}}\\left(-\\frac{|\\bm{w}|}{b} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i-\\bm{w}^T\\bm{x}_i)^2 \\right)\n",
    "\\\\\n",
    "& = \\arg \\min_{\\bm{w}}\\left(\\frac{|\\bm{w}|}{b} + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i-\\bm{w}^T\\bm{x}_i)^2 \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "**因此，最终要解决的优化问题是：**\n",
    "$$\n",
    "\\min_{\\bm{w}}\\left(\\frac{|\\bm{w}|}{b} + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i-\\bm{w}^T\\bm{x}_i)^2 \\right)\n",
    "$$\n",
    "\n",
    "**这个优化目标函数，相当于给线性模型添加了L1和L2正则化约束：**\n",
    "- $\\frac{|\\bm{w}|}{b}$是关于$\\bm{w}$的L1正则化\n",
    "- $ \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - \\bm{w}^T\\bm{x}_i)^2 $ 是平方误差损失项，为 L2 正则化项,可以看作是 $ w $ 的 L2 范数的平方乘以系数 $ \\frac{1}{2\\sigma^2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 把一句话中的每个词看作一个单元，为了构成完整的具有语义的句子，这些单元之间必然存在关联。这种关联用哪种概率模型描述更合适？简要画出相应的概率图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "待进一步学习NLP内容后回答，暂时不会"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 如果要扩展图像去噪中像素之间的关联，认为任意一个像素和周围的8个像素有关，对应的马尔可夫网络和能量函数要怎样变化？修改相应的代码，观察去噪结果是否有变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 读取原图\n",
    "orig_img = np.array(mpimg.imread('..\\origimg.jpg'), dtype=int)\n",
    "orig_img[orig_img < 128] = -1 # 黑色设置为-1\n",
    "orig_img[orig_img >= 128] = 1 # 白色设置为1\n",
    "\n",
    "# 读取带噪图像\n",
    "noisy_img = np.array(mpimg.imread('..\\\\noisyimg.jpg'), dtype=int)\n",
    "noisy_img[noisy_img < 128] = -1\n",
    "noisy_img[noisy_img >= 128] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带噪图像与原图不一致的像素比例：9.9386%\n"
     ]
    }
   ],
   "source": [
    "def compute_noise_rate(noisy, orig):\n",
    "    err = np.sum(noisy != orig)\n",
    "    return err / orig.size\n",
    "\n",
    "init_noise_rate = compute_noise_rate(noisy_img, orig_img)\n",
    "print (f'带噪图像与原图不一致的像素比例：{init_noise_rate * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算坐标(i, j)处的局部能量，考虑8个邻居（包括对角线邻居）\n",
    "def compute_energy(X, Y, i, j, alpha, alpha_diag, beta):\n",
    "    energy = -beta * X[i][j] * Y[i][j]\n",
    "    # 直接邻居和对角线邻居\n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            if dx == 0 and dy == 0:\n",
    "                continue  # 跳过像素自身\n",
    "            ni, nj = i + dx, j + dy\n",
    "            if 0 <= ni < X.shape[0] and 0 <= nj < X.shape[1]:\n",
    "                weight = alpha if (dx, dy) in [(1, 0), (-1, 0), (0, 1), (0, -1)] else alpha_diag  # 直接邻居使用alpha，对角线使用alpha_diag\n",
    "                # weight = alpha if (dx, dy) in [(0, 1), (1, 0), (-1, 0)] else alpha_diag # 这个少一个位置的降噪效果更好:)\n",
    "                energy -= weight * X[i][j] * X[ni][nj]\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代轮数：0，噪声率：0.5464%\n",
      "迭代轮数：1，噪声率：0.4675%\n",
      "迭代轮数：2，噪声率：0.4443%\n",
      "迭代轮数：3，噪声率：0.4357%\n",
      "迭代轮数：4，噪声率：0.4332%\n"
     ]
    }
   ],
   "source": [
    "# 设置超参数，考虑对角线邻居的权重\n",
    "alpha = 1.0  # 直接邻居的权重\n",
    "alpha_diag = 0.5 * alpha  # 对角线邻居的权重，通常小于直接邻居的权重\n",
    "beta = 1.0\n",
    "max_iter = 5\n",
    "\n",
    "# 逐像素优化\n",
    "X = np.copy(noisy_img)\n",
    "for k in range(max_iter):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X[i, j] = 1\n",
    "            pos_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag, beta)\n",
    "            X[i, j] = -1\n",
    "            neg_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag, beta)\n",
    "            # 将该像素设置为使能量最低的值\n",
    "            X[i, j] = 1 if pos_energy < neg_energy else -1\n",
    "    \n",
    "    # 展示图像并计算噪声率\n",
    "    # plt.figure()\n",
    "    # plt.axis('off')\n",
    "    # plt.imshow(X, cmap='binary_r')\n",
    "    # plt.show()\n",
    "    noise_rate = compute_noise_rate(X, orig_img) * 100\n",
    "    print(f'迭代轮数：{k}，噪声率：{noise_rate:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "带噪图像与原图不一致的像素比例：9.9386%  \n",
    "- [(1, 0), (-1, 0), (0, 1), (0, -1)]  \n",
    "迭代轮数：0，噪声率：0.5464%  \n",
    "迭代轮数：1，噪声率：0.4675%  \n",
    "迭代轮数：2，噪声率：0.4443%  \n",
    "迭代轮数：3，噪声率：0.4357%  \n",
    "迭代轮数：4，噪声率：0.4332%  \n",
    "- [(0, 1), (1, 0), (-1, 0)]    \n",
    "迭代轮数：0，噪声率：0.4293%  \n",
    "迭代轮数：1，噪声率：0.3064%  \n",
    "迭代轮数：2，噪声率：0.2782%  \n",
    "迭代轮数：3，噪声率：0.2746%  \n",
    "迭代轮数：4，噪声率：0.2732% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 在20 newsgroups数据集中，各个新闻事实上还包含了标题、脚注、引用等信息，而这些信息常常含有大量提示主题的关键词。因此，是否包含这些信息对分类准确率的影响非常大。阅读文档，在`fetch_20newsgroups_vectorized`函数中添加`remove`参数，把相关的主题信息移除，观察分类准确率的变化。在现实场景中，我们是否能获取到这些信息？这提示我们在利用机器学习完成实际中的任务时要注意什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现移除后分类准确率降低了。  \n",
    "\\\n",
    "在现实场景中，进行新闻分类任务，我们可能会获得全面的新闻数据，也可能获取的是被处理过的缺少此类主题相关信息，只包含正文的数据。  \n",
    "\\\n",
    "这提示我们在使用机器学习完成实际任务时，数据信息的完整性会对任务效果产生影响，要注意去**理解数据的构成和特性，做合适的数据预处理，根据数据去设计合适的算法模型**。对于一些数据，因为隐私和合规性问题，我们确实需要对数据进行处理，损失一些信息也是必要的。\n",
    "\n",
    "[sklearn.datasets.fetch_20newsgroups_vectorized](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html)  \n",
    "\n",
    ">removetuple, default=()  \n",
    "May contain any subset of (‘headers’, ‘footers’, ‘quotes’). Each of these are kinds of text that will be detected and removed from the newsgroup posts, preventing classifiers from overfitting on metadata.  \n",
    "‘headers’ removes newsgroup headers, ‘footers’ removes blocks at the ends of posts that look like signatures, and ‘quotes’ removes lines that appear to be quoting another post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from tqdm import trange\n",
    "\n",
    "train_data = fetch_20newsgroups_vectorized(subset='train', \n",
    "    normalize=False, data_home='20newsgroups')\n",
    "test_data = fetch_20newsgroups_vectorized(subset='test', \n",
    "    normalize=False, data_home='20newsgroups')\n",
    "# 移除header信息\n",
    "train_data_remove = fetch_20newsgroups_vectorized(subset='train', \n",
    "    normalize=False, remove=('headers', 'footers', 'quotes'), \n",
    "    data_home='20newsgroups')\n",
    "test_data_remove = fetch_20newsgroups_vectorized(subset='test', \n",
    "    normalize=False, remove=('headers', 'footers', 'quotes'), \n",
    "    data_home='20newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类准确率： 0.7728359001593202\n",
      "移除header后分类准确率： 0.5431492299522039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = 1.0\n",
    "mnb = MultinomialNB(alpha=alpha)\n",
    "mnb.fit(train_data.data, train_data.target)\n",
    "print('分类准确率：', mnb.score(test_data.data, test_data.target))\n",
    "mnb.fit(train_data_remove.data, train_data_remove.target)\n",
    "print('移除header后分类准确率：', mnb.score(test_data_remove.data, test_data_remove.target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
